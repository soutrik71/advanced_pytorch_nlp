{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Project is in continuation of the previous project 1 and here we will be discussing about text generation at word using LSTM:\n",
    "* Word level text generation\n",
    "* Use of custom data like new articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_pytorch_nlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_pytorch_nlp\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import torchtext\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import re\n",
    "from torchview import draw_graph\n",
    "from torcheval.metrics import MulticlassAccuracy, BinaryAccuracy\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "from src.pytorch_helpers import *\n",
    "from torch.optim import Adam\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", 100)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "import re\n",
    "import string\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "set_seed(42)\n",
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "epochs = 2\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "input_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7018\n"
     ]
    }
   ],
   "source": [
    "json_data = json.load(open(\"./data/bloomberg_quint_news.json\", \"r\"))\n",
    "print(len(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>short_description</th>\n",
       "      <th>author</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>category</th>\n",
       "      <th>raw_description</th>\n",
       "      <th>description</th>\n",
       "      <th>publisher</th>\n",
       "      <th>scraped_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.bloombergquint.com/markets/all-you-need-to-know-going-into-trade-on-september-23-2</td>\n",
       "      <td>All You Need To Know Going Into Trade On September 23</td>\n",
       "      <td>Stocks in the news, big brokerage calls of the day, complete trade setup and much more!</td>\n",
       "      <td>Darshan A Nakhwa</td>\n",
       "      <td>23 Sep 2021, 7:05 AM IST</td>\n",
       "      <td>23 Sep 2021, 7:05 AM IST</td>\n",
       "      <td>Markets</td>\n",
       "      <td>&lt;div class=\"story-element story-element-text\"&gt;&lt;div&gt;Asian stocks were steady early Thursday after...</td>\n",
       "      <td>Asian stocks were steady early Thursday after U.S. shares took in their stride the prospect of a...</td>\n",
       "      <td>https://www.bloombergquint.com/</td>\n",
       "      <td>2021-09-24 00:01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.bloombergquint.com/business/bridgestone-ceo-backs-safe-tokyo-olympics-dials-back-mar...</td>\n",
       "      <td>Bridgestone CEO Backs Safe Tokyo Olympics, Dials Back Marketing</td>\n",
       "      <td>Bridgestone CEO Backs Safe Tokyo Olympics, Dials Back Marketing</td>\n",
       "      <td>Shiho Takezawa &amp;</td>\n",
       "      <td>23 Apr 2021, 5:35 AM IST</td>\n",
       "      <td>23 Apr 2021, 6:35 AM IST</td>\n",
       "      <td>Business</td>\n",
       "      <td>&lt;div class=\"story-element story-element-text\"&gt;&lt;div&gt;(Bloomberg) -- Bridgestone Corp. will support...</td>\n",
       "      <td>Bridgestone Corp. will support the Tokyo Olympics and Paralympic games as a ,  as long as the s...</td>\n",
       "      <td>https://www.bloombergquint.com/</td>\n",
       "      <td>2021-09-24 00:01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.bloombergquint.com/markets/stocks-to-watch-hcl-tech-cyient-mm-financial-services-tat...</td>\n",
       "      <td>Stocks To Watch: HCL Tech, Cyient, M&amp;M Financial Services, Tata Motors, Torrent Power, Wipro</td>\n",
       "      <td>Here are the stocks to watch in trade today...</td>\n",
       "      <td>BQ Desk</td>\n",
       "      <td>23 Apr 2021, 7:29 AM IST</td>\n",
       "      <td>23 Apr 2021, 7:29 AM IST</td>\n",
       "      <td>Markets</td>\n",
       "      <td>&lt;div class=\"story-element story-element-text\"&gt;&lt;div&gt;Indian equity benchmarks reversed losses made...</td>\n",
       "      <td>Indian equity benchmarks reversed losses made in the first half of the session to snap a two-ses...</td>\n",
       "      <td>https://www.bloombergquint.com/</td>\n",
       "      <td>2021-09-24 00:01:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   url  \\\n",
       "0       https://www.bloombergquint.com/markets/all-you-need-to-know-going-into-trade-on-september-23-2   \n",
       "1  https://www.bloombergquint.com/business/bridgestone-ceo-backs-safe-tokyo-olympics-dials-back-mar...   \n",
       "2  https://www.bloombergquint.com/markets/stocks-to-watch-hcl-tech-cyient-mm-financial-services-tat...   \n",
       "\n",
       "                                                                                          title  \\\n",
       "0                                         All You Need To Know Going Into Trade On September 23   \n",
       "1                               Bridgestone CEO Backs Safe Tokyo Olympics, Dials Back Marketing   \n",
       "2  Stocks To Watch: HCL Tech, Cyient, M&M Financial Services, Tata Motors, Torrent Power, Wipro   \n",
       "\n",
       "                                                                         short_description  \\\n",
       "0  Stocks in the news, big brokerage calls of the day, complete trade setup and much more!   \n",
       "1                          Bridgestone CEO Backs Safe Tokyo Olympics, Dials Back Marketing   \n",
       "2                                           Here are the stocks to watch in trade today...   \n",
       "\n",
       "             author              date_created             date_modified  category  \\\n",
       "0  Darshan A Nakhwa  23 Sep 2021, 7:05 AM IST  23 Sep 2021, 7:05 AM IST   Markets   \n",
       "1  Shiho Takezawa &  23 Apr 2021, 5:35 AM IST  23 Apr 2021, 6:35 AM IST  Business   \n",
       "2           BQ Desk  23 Apr 2021, 7:29 AM IST  23 Apr 2021, 7:29 AM IST   Markets   \n",
       "\n",
       "                                                                                       raw_description  \\\n",
       "0  <div class=\"story-element story-element-text\"><div>Asian stocks were steady early Thursday after...   \n",
       "1  <div class=\"story-element story-element-text\"><div>(Bloomberg) -- Bridgestone Corp. will support...   \n",
       "2  <div class=\"story-element story-element-text\"><div>Indian equity benchmarks reversed losses made...   \n",
       "\n",
       "                                                                                           description  \\\n",
       "0  Asian stocks were steady early Thursday after U.S. shares took in their stride the prospect of a...   \n",
       "1   Bridgestone Corp. will support the Tokyo Olympics and Paralympic games as a ,  as long as the s...   \n",
       "2  Indian equity benchmarks reversed losses made in the first half of the session to snap a two-ses...   \n",
       "\n",
       "                         publisher           scraped_at  \n",
       "0  https://www.bloombergquint.com/  2021-09-24 00:01:25  \n",
       "1  https://www.bloombergquint.com/  2021-09-24 00:01:26  \n",
       "2  https://www.bloombergquint.com/  2021-09-24 00:01:26  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleanup(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"description\"] = news_df[\"description\"].apply(basic_cleanup)\n",
    "news_df[\"title\"] = news_df[\"title\"].apply(basic_cleanup)\n",
    "news_df[\"short_description\"] = news_df[\"short_description\"].apply(basic_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating text in one field only\n",
    "news_df[\"Complete_Text\"] = (\n",
    "    news_df[\"title\"] + \" : \" + news_df[\"short_description\"] + \" : \" + news_df[\"description\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_df[\"Complete_Text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dump = \" \".join(news_df[\"Complete_Text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchVocabulary:\n",
    "    \"\"\"\n",
    "    Class to create the vocabulary for the text data\n",
    "\n",
    "    Args:\n",
    "    freq_threshold: int: frequency threshold for the words\n",
    "    max_size: int: maximum size of the vocabulary\n",
    "    tokenizer: tokenizer: tokenizer to tokenize the text\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, freq_threshold, max_size, tokenizer) -> None:\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def tokenization(self, text):\n",
    "        return self.tokenizer(text)\n",
    "\n",
    "    def build_vocabulary(self, sentence_list: list):\n",
    "        \"\"\"Build the vocabulary from the sentence list\"\"\"\n",
    "        # calculate the frequencies of each word first to remove the words with freq < freq_threshold\n",
    "        overall_word_counts = Counter()  # init the freq dict\n",
    "        idx = 4  # index from which we want our dict to start. We already used 4 indexes for pad, start, end, unk\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            sentence_word_counts = Counter(self.tokenization(sentence))\n",
    "            # Update the overall word counts\n",
    "            overall_word_counts.update(sentence_word_counts)\n",
    "\n",
    "        # remove low freq words\n",
    "        frequencies = {\n",
    "            k: v for k, v in overall_word_counts.items() if v >= self.freq_threshold\n",
    "        }\n",
    "\n",
    "        # limit the vocab size to max_size\n",
    "        frequencies = dict(\n",
    "            sorted(frequencies.items(), key=lambda x: -x[1])[: self.max_size]\n",
    "        )\n",
    "\n",
    "        # update stoi and itos post index 4 for the new words\n",
    "        for word in frequencies:\n",
    "            self.stoi[word] = idx\n",
    "            self.itos[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "    def create_text_vectors(self, text):\n",
    "        \"\"\"Convert the text to vectors\"\"\"\n",
    "        tokens = self.tokenization(text)\n",
    "        vec = [self.stoi.get(token, self.stoi[\"<UNK>\"]) for token in tokens]\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = TorchVocabulary(1, 100000, get_tokenizer(\"basic_english\"))\n",
    "vocabulary.build_vocabulary([news_dump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57497"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary) # 4 more than the actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaking the data into samples of fixed size\n",
    "token_ls = vocabulary.tokenization(news_dump)\n",
    "data_sample = [\n",
    "    token_ls[i : (i + input_len + 1)] for i in range(0, len(token_ls) - batch_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all you need to know going into trade on september 23 stocks in the news big brokerage calls of the day complete trade setup and much more asian stocks were steady early thursday after us shares took in their stride the prospect of a reduction in federal reserve stimulus as early as november the treasury yield curve flattened stocks rose in australia and dipped in south korea japan is shut for a holiday and hong kong will reopen from one us futures climbed after the sp 500 pushed higher for the first time in five sessions and the nasdaq 100 advanced fed chair jerome powell said the central bank could begin scaling back asset purchases in november and complete the process by mid2022 officials also revealed a growing inclination'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you need to know going into trade on september 23 stocks in the news big brokerage calls of the day complete trade setup and much more asian stocks were steady early thursday after us shares took in their stride the prospect of a reduction in federal reserve stimulus as early as november the treasury yield curve flattened stocks rose in australia and dipped in south korea japan is shut for a holiday and hong kong will reopen from one us futures climbed after the sp 500 pushed higher for the first time in five sessions and the nasdaq 100 advanced fed chair jerome powell said the central bank could begin scaling back asset purchases in november and complete the process by mid2022 officials also revealed a growing inclination to'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data_sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 129)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_sample[0]), len(data_sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57493"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(token_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(x) for x in data_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, samples, vocabulary):\n",
    "        self.samples = samples\n",
    "        self.vocabulary = vocabulary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        samples = self.samples[idx]\n",
    "        input_txt = torch.tensor(\n",
    "            self.vocabulary.create_text_vectors(\" \".join(samples[:-1])),\n",
    "            dtype=torch.long,\n",
    "        ).to(device)\n",
    "\n",
    "        target_txt = torch.tensor(\n",
    "            self.vocabulary.create_text_vectors(\" \".join(samples[1:])), dtype=torch.long\n",
    "        ).to(device)\n",
    "\n",
    "        return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsDataset(data_sample, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128]), torch.Size([128]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dataset))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, drop_last=True, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerationLSTM(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_dim, num_layers, drop_out=0.2\n",
    "    ) -> None:\n",
    "        super(TextGenerationLSTM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return h0, c0\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_states = self.init_hidden(x.size(0))\n",
    "        embedded = self.embedding_layer(x)\n",
    "        out, (h_n, c_n) = self.lstm_layer(embedded, hidden_states)\n",
    "        # print(out.shape)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out, (h_n, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGenerationLSTM(\n",
       "  (embedding_layer): Embedding(57497, 100)\n",
       "  (lstm_layer): LSTM(100, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=57497, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lstm_model = TextGenerationLSTM(len(vocabulary), 100, 256, 2).to(device)\n",
    "word_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_module(\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    train_losses: list,\n",
    "):\n",
    "\n",
    "    # setting model to train mode\n",
    "    model.train()\n",
    "    pbar = tqdm(train_dataloader)\n",
    "\n",
    "    # batch metrics\n",
    "    train_loss = 0\n",
    "    processed_batch = 0\n",
    "\n",
    "    for idx, (data, label) in enumerate(pbar):\n",
    "        # setting up device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward pass output\n",
    "        preds, _ = model(data)\n",
    "\n",
    "        # calc loss\n",
    "        loss = criterion(preds, label.view(-1))\n",
    "        train_loss += loss.item()\n",
    "        # print(f\"training loss for batch {idx} is {loss}\")\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()  # flush out  existing grads\n",
    "        loss.backward()  # back prop of weights wrt loss\n",
    "        optimizer.step()  # optimizer step -> minima\n",
    "\n",
    "        # updating batch count\n",
    "        processed_batch += 1\n",
    "\n",
    "        pbar.set_description(f\"Avg Train Loss: {train_loss/processed_batch}\")\n",
    "\n",
    "    # updating epoch metrics\n",
    "    train_losses.append(train_loss / processed_batch)\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_module(\n",
    "    model: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    test_losses,\n",
    "):\n",
    "    # setting model to eval mode\n",
    "    model.eval()\n",
    "    pbar = tqdm(test_dataloader)\n",
    "\n",
    "    # batch metrics\n",
    "    test_loss = 0\n",
    "    processed_batch = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for idx, (data, label) in enumerate(pbar):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            # predictions\n",
    "            preds = model(data)\n",
    "            # print(preds.shape)\n",
    "            # print(label.shape)\n",
    "\n",
    "            # loss calc\n",
    "            loss = criterion(preds, label)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # updating batch count\n",
    "            processed_batch += 1\n",
    "\n",
    "            pbar.set_description(f\"Avg Test Loss: {test_loss/processed_batch} \")\n",
    "\n",
    "        # updating epoch metrics\n",
    "        test_losses.append(test_loss / processed_batch)\n",
    "\n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(word_lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 0/32481 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 6.7252771457794855: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 32480/32481 [1:09:21<00:00,  7.80it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [128] at entry 0 and [127] at entry 55",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d7277cee67f9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     train_losses, train_metrics = train_module(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mword_lstm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-3b1b0a964d16>\u001b[0m in \u001b[0;36mtrain_module\u001b[0;34m(model, device, train_dataloader, optimizer, criterion, train_losses)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprocessed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# setting up device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [128] at entry 0 and [127] at entry 55"
     ]
    }
   ],
   "source": [
    "# Place holders----\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_losses, train_metrics = train_module(\n",
    "        word_lstm_model,\n",
    "        device,\n",
    "        train_dataloader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_losses,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
